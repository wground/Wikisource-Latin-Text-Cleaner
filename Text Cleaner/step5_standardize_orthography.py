#!/usr/bin/env python3
"""
Step 5: Standardize Orthography
Standardizes Latin orthography by removing diacritics, normalizing ligatures,
converting j->i and v->u, and making everything lowercase for consistent
tokenization in LLM training.
"""

import os
import re
import unicodedata
import logging
from progress_tracker import ProgressTracker, get_file_stats

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def normalize_medieval_variants(text):
    """
    Normalize medieval/late Latin orthographic variants to classical forms.
    This function standardizes common medieval spelling variants before other transformations.
    Based on scholarly research into medieval Latin orthography.
    """
    # Medieval H ‚Üí CH variants (michi ‚Üí mihi, nichil ‚Üí nihil, etc.)
    h_to_ch_variants = {
        # Core pronouns and common words with 'h' changed to 'ch'
        r'\bmichi\b': 'mihi',           # to me (dative of ego)
        r'\btichi\b': 'tibi',           # to you (dative of tu) 
        r'\bsichi\b': 'sibi',           # to himself/herself (dative of se)
        r'\bnichil\b': 'nihil',         # nothing
        r'\bnichilo\b': 'nihilo',       # nothing (ablative)
        r'\bnichilum\b': 'nihilum',     # nothing (accusative)
        r'\bmichil\b': 'mihil',         # variant of nihil
        r'\bmacina\b': 'machina',       # machine
        r'\bpulcer\b': 'pulcher',       # beautiful
        r'\bsepulcrum\b': 'sepulchrum', # tomb
        
        # Spanish/Iberian variants (nichi ‚Üí nihil, mici ‚Üí mihi)
        r'\bnichi\b': 'nihil',
        r'\bmici\b': 'mihi',
        r'\barcivum\b': 'archivum',     # archive
        
        # Other h-loss variants
        r'\babere\b': 'habere',         # to have (h-loss)
        r'\bomines\b': 'homines',       # men (h-loss)
        r'\bonor\b': 'honor',           # honor (h-loss)
        r'\bora\b(?!\w)': 'hora',       # hour (careful not to match 'ora' = pray)
        r'\bumanus\b': 'humanus',       # human (h-loss)
        
        # Reverse h-addition (where h was added incorrectly)
        r'\bchorona\b': 'corona',       # crown (incorrect h-addition)
        r'\brhethor\b': 'rhetor',       # rhetorician 
    }
    
    # Medieval consonant variants
    consonant_variants = {
        # TI ‚Üí CI variants (divitiae ‚Üí diviciae, tertius ‚Üí tercius)
        r'\bdiviciae\b': 'divitiae',    # riches
        r'\bdivicie\b': 'divitiae',     # riches (alternate)
        r'\btercius\b': 'tertius',      # third
        r'\bvicium\b': 'vitium',        # vice/fault
        r'\bnegocium\b': 'negotium',    # business
        r'\bprecium\b': 'pretium',      # price
        r'\bspacium\b': 'spatium',      # space
        r'\bpaciens\b': 'patiens',      # patient
        r'\bgracie\b': 'gratiae',       # thanks/graces
        r'\bjusticia\b': 'justitia',    # justice
        
        # MN ‚Üí MPN variants (damnum ‚Üí dampnum)
        r'\bdampnum\b': 'damnum',       # damage
        r'\balumpnus\b': 'alumnus',     # student/foster child
        r'\bsompnus\b': 'somnus',       # sleep
        r'\bhiempns\b': 'hiems',        # winter
        r'\bcolumpna\b': 'columna',     # column
        r'\bsolempnis\b': 'sollemnis',  # solemn
        
        # Double consonant variations
        r'\btranquilitas\b': 'tranquillitas', # tranquility (single ‚Üí double l)
        r'\bAffrica\b': 'Africa',       # Africa (double ‚Üí single f)
        r'\boccasio\b': 'occasio',      # occasion
        r'\bopprobrium\b': 'oprobrium', # reproach
        r'\bassidere\b': 'assidere',    # to sit by
        
        # AE ‚Üí E simplification (medieval trend)
        r'\bcese\b': 'caese',           # cut (past participle)
        r'\bquedam\b': 'quaedam',       # certain (feminine)
        r'\bpretor\b': 'praetor',       # praetor
        r'\bequs\b': 'aequus',          # equal
        r'\bequalitas\b': 'aequalitas', # equality
        
        # OE ‚Üí E simplification  
        r'\bpena\b': 'poena',           # punishment
        r'\bfenum\b': 'foenum',         # hay
        r'\bfedus\b': 'foedus',         # treaty/foul
        
        # B ‚Üí V variants (common medieval confusion)
        r'\babsoluo\b': 'absolvo',      # I absolve
        r'\buiuo\b': 'vivo',            # I live
        r'\bbibo\b': 'vivo',            # incorrect b for v
        
        # Medieval spelling normalizations
        r'\bquoniam\b': 'quoniam',      # because (standardize)
        r'\bquamuis\b': 'quamvis',      # although  
        r'\bquamcumque\b': 'quamcumque', # whenever
        r'\bquemadmodum\b': 'quemadmodum', # just as
    }
    
    # Numerical and ordinal variants
    numerical_variants = {
        r'\bprimus\b': 'primus',        # first (standardize)
        r'\bsecundus\b': 'secundus',    # second
        r'\btercius\b': 'tertius',      # third (ci ‚Üí ti)
        r'\bquartus\b': 'quartus',      # fourth
        r'\bquintus\b': 'quintus',      # fifth
        r'\bsextus\b': 'sextus',        # sixth
        r'\bseptimus\b': 'septimus',    # seventh
        r'\boctauus\b': 'octavus',      # eighth
        r'\bnonus\b': 'nonus',          # ninth
        r'\bdecimus\b': 'decimus',      # tenth
    }
    
    # Apply all variant replacements (case-insensitive)
    variant_groups = [h_to_ch_variants, consonant_variants, numerical_variants]
    replacements_made = 0
    
    for variant_dict in variant_groups:
        for pattern, replacement in variant_dict.items():
            original_text = text
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
            if text != original_text:
                count = len(re.findall(pattern, original_text, re.IGNORECASE))
                replacements_made += count
                stripped_pattern = pattern.strip(r'\b')
                logger.debug(f"Normalized {count} instances of medieval variant: {stripped_pattern} ‚Üí {replacement}")
    
    return text, replacements_made

def remove_diacritics(text):
    """Remove all diacritical marks from Latin text."""
    # Comprehensive diacritic replacements
    diacritic_replacements = {
        # Macrons (long vowel markers)
        'ƒÅ': 'a', 'ƒì': 'e', 'ƒ´': 'i', '≈ç': 'o', '≈´': 'u', '»≥': 'y',
        'ƒÄ': 'a', 'ƒí': 'e', 'ƒ™': 'i', '≈å': 'o', '≈™': 'u', '»≤': 'y',
        
        # Breves (short vowel markers)
        'ƒÉ': 'a', 'ƒï': 'e', 'ƒ≠': 'i', '≈è': 'o', '≈≠': 'u',
        'ƒÇ': 'a', 'ƒî': 'e', 'ƒ¨': 'i', '≈é': 'o', '≈¨': 'u',
        
        # Acute accents
        '√°': 'a', '√©': 'e', '√≠': 'i', '√≥': 'o', '√∫': 'u', '√Ω': 'y',
        '√Å': 'a', '√â': 'e', '√ç': 'i', '√ì': 'o', '√ö': 'u', '√ù': 'y',
        
        # Grave accents
        '√†': 'a', '√®': 'e', '√¨': 'i', '√≤': 'o', '√π': 'u',
        '√Ä': 'a', '√à': 'e', '√å': 'i', '√í': 'o', '√ô': 'u',
        
        # Circumflex accents
        '√¢': 'a', '√™': 'e', '√Æ': 'i', '√¥': 'o', '√ª': 'u', '≈∑': 'y',
        '√Ç': 'a', '√ä': 'e', '√é': 'i', '√î': 'o', '√õ': 'u', '≈∂': 'y',
        
        # Other diacritics that might appear
        '√§': 'a', '√´': 'e', '√Ø': 'i', '√∂': 'o', '√º': 'u', '√ø': 'y',
        '√Ñ': 'a', '√ã': 'e', '√è': 'i', '√ñ': 'o', '√ú': 'u', '≈∏': 'y',
        '√£': 'a', '√±': 'n', '√µ': 'o', '√ß': 'c',
        '√É': 'a', '√ë': 'n', '√ï': 'o', '√á': 'c',
        
        # Ring above/below
        '√•': 'a', '≈Ø': 'u', '√Ö': 'a', '≈Æ': 'u',
        
        # Cedilla
        '√ß': 'c', '≈ü': 's', '≈£': 't',
        '√á': 'c', '≈û': 's', '≈¢': 't',
        
        # Caron/hacek
        'ƒç': 'c', 'ƒè': 'd', 'ƒõ': 'e', '≈à': 'n', '≈ô': 'r', '≈°': 's', '≈•': 't', '≈æ': 'z',
        'ƒå': 'c', 'ƒé': 'd', 'ƒö': 'e', '≈á': 'n', '≈ò': 'r', '≈†': 's', '≈§': 't', '≈Ω': 'z',
        
        # Double acute
        '≈ë': 'o', '≈±': 'u',
        '≈ê': 'o', '≈∞': 'u',
        
        # Ogonek
        'ƒÖ': 'a', 'ƒô': 'e', 'ƒØ': 'i', '≈≥': 'u',
        'ƒÑ': 'a', 'ƒò': 'e', 'ƒÆ': 'i', '≈≤': 'u',
    }
    
    # Apply explicit replacements first
    for diacritic, standard in diacritic_replacements.items():
        text = text.replace(diacritic, standard)
    
    # Use Unicode normalization as backup for any remaining diacritics
    # NFD decomposes characters into base + combining marks, then filter out the marks
    normalized = unicodedata.normalize('NFD', text)
    without_accents = ''.join(
        char for char in normalized 
        if unicodedata.category(char) != 'Mn'  # Mn = Nonspacing_Mark (combining diacritics)
    )
    
    return without_accents

def normalize_ligatures(text):
    """Convert ligatures to their component letters."""
    ligature_replacements = {
        # Latin ligatures
        '√¶': 'ae', '√Ü': 'ae',
        '≈ì': 'oe', '≈í': 'oe',
        
        # Other possible ligatures
        'Ô¨Ä': 'ff', 'Ô¨Å': 'fi', 'Ô¨Ç': 'fl', 'Ô¨É': 'ffi', 'Ô¨Ñ': 'ffl',
        'Ô¨Ö': 'st', 'Ô¨Ü': 'st',
        
        # Historical ligatures that might appear in old texts
        'ƒ≥': 'ij', 'ƒ≤': 'ij',
        
        # Et ligature
        '&': 'et',
    }
    
    for ligature, replacement in ligature_replacements.items():
        text = text.replace(ligature, replacement)
    
    return text

def normalize_medieval_characters(text):
    """Convert medieval character variants to standard forms."""
    medieval_replacements = {
        # Medieval v/u normalization - convert all v to u
        'v': 'u',
        'V': 'u',
        
        # Medieval j/i normalization - convert all j to i  
        'j': 'i',
        'J': 'i',
        
        # Medieval variants of other letters
        '≈ø': 's',  # Long s
        ' É': 's',  # Another form of long s
        '√ü': 'ss', # German sz ligature (might appear in Latin texts)
        
        # Medieval punctuation variants
        '¬∂': '',   # Paragraph mark (pilcrow)
        '¬ß': '',   # Section mark
        '‚Ä†': '',   # Dagger
        '‚Ä°': '',   # Double dagger
        
        # Medieval abbreviation marks (remove rather than expand)
        '‚Ñ•': '',   # Ounce mark
        '‚Ñû': '',   # Prescription mark
        '‚Ñü': '',   # Response mark
        
        # Tironian notes (medieval shorthand)
        '‚Åä': 'et', # Tironian et
        '‚Ñà': '',   # Scruple mark
    }
    
    for medieval, replacement in medieval_replacements.items():
        text = text.replace(medieval, replacement)
    
    return text

def convert_to_lowercase(text):
    """Convert all text to lowercase."""
    return text.lower()

def clean_letter_spacing(text):
    """Fix common letter spacing issues that might occur after normalization."""
    # Remove excessive spaces around punctuation
    text = re.sub(r'\s+([,.;:!?])', r'\1', text)
    text = re.sub(r'([,.;:!?])\s+', r'\1 ', text)
    
    # Standardize quotation mark spacing
    text = re.sub(r'\s*(["\'""])\s*', r' \1', text)
    
    # Fix spacing around parentheses
    text = re.sub(r'\s*\(\s*', r' (', text)
    text = re.sub(r'\s*\)\s*', r') ', text)
    
    return text

def standardize_punctuation_final(text):
    """Final punctuation standardization after orthographic changes."""
    # Normalize quotation marks to simple ASCII
    quote_replacements = {
        '"': '"', '"': '"', ''': "'", ''': "'",
        '¬´': '"', '¬ª': '"', '‚Äö': "'", '‚Äû': '"',
        '‚Äπ': "'", '‚Ä∫': "'", '‚Äõ': "'", '"': '"'
    }
    
    for fancy_quote, simple_quote in quote_replacements.items():
        text = text.replace(fancy_quote, simple_quote)
    
    # Normalize dashes
    text = re.sub(r'[‚Äì‚Äî]', '-', text)
    
    # Normalize ellipses
    text = re.sub(r'‚Ä¶', '...', text)
    
    return text

def standardize_orthography(text):
    """Apply all orthographic standardization steps in the correct order."""
    stats = {
        'variants_normalized': 0,
        'diacritics_removed': 0,
        'ligatures_normalized': 0,
        'medieval_chars_converted': 0
    }
    
    logger.debug("Normalizing medieval variants FIRST...")
    text, variants_count = normalize_medieval_variants(text)
    stats['variants_normalized'] = variants_count
    
    logger.debug("Removing diacritics...")
    original_len = len(text)
    text = remove_diacritics(text)
    # Estimate diacritics removed (rough heuristic)
    stats['diacritics_removed'] = max(0, original_len - len(text))
    
    logger.debug("Normalizing ligatures...")
    original_text = text
    text = normalize_ligatures(text)
    stats['ligatures_normalized'] = len(re.findall(r'ae|oe|et', text)) - len(re.findall(r'ae|oe|et', original_text))
    
    logger.debug("Converting medieval characters...")
    text = normalize_medieval_characters(text)
    
    logger.debug("Converting to lowercase...")
    text = convert_to_lowercase(text)
    
    logger.debug("Cleaning letter spacing...")
    text = clean_letter_spacing(text)
    
    logger.debug("Final punctuation standardization...")
    text = standardize_punctuation_final(text)
    
    return text, stats

def process_directory(input_dir, output_dir):
    """Process all txt files in a directory with enhanced progress tracking and orthographic variant normalization."""
    if not os.path.exists(input_dir):
        logger.warning(f"Input directory {input_dir} does not exist")
        return 0
        
    os.makedirs(output_dir, exist_ok=True)
    
    # Create reports directory
    report_dir = os.path.join(output_dir, "orthography_reports")  
    os.makedirs(report_dir, exist_ok=True)
    
    txt_files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]
    
    # Initialize enhanced progress tracker
    dir_name = os.path.basename(input_dir)
    progress = ProgressTracker(f"Orthographic Standardization: {dir_name}", len(txt_files))
    
    # Aggregate statistics
    total_variants_normalized = 0
    total_diacritics_removed = 0
    total_ligatures_normalized = 0
    
    for filename in txt_files:
        input_path = os.path.join(input_dir, filename)
        output_path = os.path.join(output_dir, filename)
        
        # Get file stats and start progress tracking
        file_stats = get_file_stats(input_path)
        book_title = progress.start_file(filename, file_stats['size'])
        
        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Apply enhanced orthographic standardization
            standardized_content, ortho_stats = standardize_orthography(content)
            
            # Save standardized content
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(standardized_content)
            
            # Update aggregate statistics
            total_variants_normalized += ortho_stats['variants_normalized']
            total_diacritics_removed += ortho_stats['diacritics_removed']
            total_ligatures_normalized += ortho_stats['ligatures_normalized']
            
            # Log detailed progress
            if ortho_stats['variants_normalized'] > 0:
                progress.log_progress(f"Normalized {ortho_stats['variants_normalized']} medieval variants")
            if ortho_stats['diacritics_removed'] > 0:
                progress.log_progress(f"Removed {ortho_stats['diacritics_removed']} diacritics")
            
            progress.finish_file(success=True, 
                               lines_processed=file_stats.get('lines', 0),
                               bytes_processed=len(standardized_content.encode('utf-8')),
                               expansions_made=ortho_stats['variants_normalized'])
            
        except Exception as e:
            error_msg = f"Orthography standardization error: {e}"
            progress.finish_file(success=False, error_msg=error_msg)
    
    # Update final progress statistics
    progress.stats.update({
        'expansions_made': total_variants_normalized,  # Use expansions field for variant normalizations
    })
    
    # Print enhanced progress summary
    final_stats = progress.print_summary()
    
    # Save processing report with orthographic details
    try:
        report_path = os.path.join(report_dir, "orthography_summary.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=== Enhanced Orthographic Standardization Report ===\n\n")
            f.write(f"Files processed: {final_stats['files_processed']}\n")
            f.write(f"Medieval variants normalized: {total_variants_normalized}\n")
            f.write(f"Diacritics removed: {total_diacritics_removed}\n") 
            f.write(f"Ligatures normalized: {total_ligatures_normalized}\n")
            f.write(f"Errors encountered: {final_stats['errors']}\n\n")
            f.write("Orthographic features applied:\n")
            f.write("‚úì Medieval variant normalization (michi‚Üímihi, nichil‚Üínihil, etc.)\n")
            f.write("‚úì Comprehensive diacritic removal\n")
            f.write("‚úì Ligature normalization (√¶‚Üíae, ≈ì‚Üíoe)\n")
            f.write("‚úì Medieval character conversion (j‚Üíi, v‚Üíu)\n")
            f.write("‚úì Case normalization (all lowercase)\n")
            f.write("‚úì Punctuation standardization\n")
        
        progress.log_progress(f"Saved orthography report to {report_path}")
    except Exception as e:
        progress.log_progress(f"Could not save orthography report: {e}", "warning")
    
    return final_stats['files_processed']

def main():
    base_input = "headings_removed"
    base_output = "orthography_standardized"
    
    logger.info("=== Step 5: Enhanced Orthographic Standardization ===")
    logger.info("Features: Medieval variant normalization, diacritic removal, case standardization")
    
    # Create output directory structure
    os.makedirs(base_output, exist_ok=True)
    
    # Updated to handle new mixed genre directory structure
    directories_to_process = [
        ("classical/prose", "classical/prose"),
        ("classical/poetry", "classical/poetry"),
        ("classical/mixed", "classical/mixed"),
        ("post_classical/prose", "post_classical/prose"),
        ("post_classical/poetry", "post_classical/poetry"),
        ("post_classical/mixed", "post_classical/mixed"),
    ]
    
    total_processed = 0
    
    for input_subdir, output_subdir in directories_to_process:
        input_dir = os.path.join(base_input, input_subdir)
        output_dir = os.path.join(base_output, output_subdir)
        
        if os.path.exists(input_dir):
            logger.info(f"Processing {input_subdir}...")
            processed = process_directory(input_dir, output_dir)
            total_processed += processed
            logger.info(f"Enhanced orthographic standardization completed for {processed} files in {input_subdir}")
        else:
            logger.debug(f"Skipping non-existent directory: {input_subdir}")
    
    logger.info(f"\n=== Enhanced Orthographic Standardization Summary ===")
    logger.info(f"‚úÖ Total files processed: {total_processed}")
    logger.info(f"üî§ Features applied:")
    logger.info(f"   ‚Ä¢ Medieval variant normalization (michi‚Üímihi, nichil‚Üínihil, etc.)")
    logger.info(f"   ‚Ä¢ Comprehensive diacritic removal (ƒÅ‚Üía, ƒì‚Üíe, etc.)")
    logger.info(f"   ‚Ä¢ Ligature standardization (√¶‚Üíae, ≈ì‚Üíoe)")
    logger.info(f"   ‚Ä¢ Medieval character conversion (j‚Üíi, v‚Üíu)")
    logger.info(f"   ‚Ä¢ Case normalization (all lowercase)")
    logger.info(f"   ‚Ä¢ Punctuation standardization")
    logger.info(f"üìã Detailed reports saved in orthography_reports/ directories")
    logger.info(f"üéØ Latin texts now have standardized orthography for LLM training!")

if __name__ == "__main__":
    main()